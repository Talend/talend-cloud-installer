---
profile::kafka::zookeeper_nodes: "%{::zookeeper_nodes}"
profile::kafka::storage_device: "%{::storage_device}"
profile::kafka::kafka_cluster_id: "%{::kafka_cluster_id}"
profile::kafka::kafka_yaml_profile_name: "%{::kafka_yaml_profile_name}"

profile::common::cloudwatchlogs::recursive: false
cloudwatchlog_files:
  "/talend/tic/%{::main_stack}/%{::sub_stack}/%{::puppet_role}/var/log/cfn-init.log":
    path: '/var/log/cfn-init.log'
  "/talend/tic/%{::main_stack}/%{::sub_stack}/%{::puppet_role}/var/log/cfn-init-cmd.log":
    path: '/var/log/cfn-init-cmd.log'
  "/talend/tic/%{::main_stack}/%{::sub_stack}/%{::puppet_role}/var/log/messages":
    path: '/var/log/messages'
  "/talend/tic/%{::main_stack}/%{::sub_stack}/%{::puppet_role}/var/log/secure":
    path: '/var/log/secure'
  "/talend/tic/%{::main_stack}/%{::sub_stack}/%{::puppet_role}/var/log/audit/audit.log":
    path: '/var/log/audit/audit.log'
    datetime_format: '%s'
  "/talend/tic/%{::main_stack}/%{::sub_stack}/%{::puppet_role}/opt/kafka/logs/server.log":
    path: '/opt/kafka/logs/server.log'
  "/talend/tic/%{::main_stack}/%{::sub_stack}/%{::puppet_role}/opt/kafka/logs/state-change.log":
    path: '/opt/kafka/logs/state-change.log'
  "/talend/tic/%{::main_stack}/%{::sub_stack}/%{::puppet_role}/opt/kafka/logs/kafka-request.log":
    path: '/opt/kafka/logs/kafka-request.log'
  "/talend/tic/%{::main_stack}/%{::sub_stack}/%{::puppet_role}/opt/kafka/logs/log-cleaner.log":
    path: '/opt/kafka/logs/log-cleaner.log'
  "/talend/tic/%{::main_stack}/%{::sub_stack}/%{::puppet_role}/opt/kafka/logs/controller.log":
    path: '/opt/kafka/logs/controller.log'
  "/talend/tic/%{::main_stack}/%{::sub_stack}/%{::puppet_role}/opt/kafka/logs/kafka-authorizer.log":
    path: '/opt/kafka/logs/kafka-authorizer.log'


cloudwatch::metrics:
  DiskSpaceKafka:
    type              : diskspace
    params            : '-f /var/lib/kafka'
    unit              : Percent
    description       : 'Percentage of used disk space for kafka topics'
    statistic         : 'Average'
    period            : 300
    evaluationperiods : 3
    threshold         : 80
    comparisonoperator: "GreaterThanThreshold"

# Default profile
profile::kafka::kafka_broker_config:
  log.cleanup.policy: 'delete'
  log.retention.bytes: "268435456" # 256 MiB, per partition
  log.segment.bytes: "134217728"   # 128 MiB max per segment
  log.roll.ms: "1200000"           # a segment will be used (written) for max 20mn (after 20mn, a new file is created)
  log.retention.ms: "43200000"     # 12h

# We can have several kafka cluster
kafka_infra_logs_cluster_ha: # estimated max cluster size: 102 GiB + customers offsets => 60GiB per node
  kafka_topics_default_partitions: 12
  kafka_topics_default_replication: 2
  log_level: 'INFO'
  kafka_broker_config:
    log.cleanup.policy: 'delete'
    log.retention.bytes: "268435456" # 256 MiB, per partition
    log.segment.bytes: "134217728"   # 128 MiB max per segment
    log.roll.ms: "1200000"           # a segment will be used (written) for max 20mn (after 20mn, a new file is created)
    log.retention.ms: "43200000"     # 12h
  topics:
    tpsvclogs:
      topic_options:
        retention.ms: "43200000"      # 12h
        retention.bytes: "2147483648" # 2 GiB per partition
    systemlogs:
      topic_options:
        retention.ms: "43200000"      # 12h
        retention.bytes: "2147483648" # 2 GiB per partition
    zipkin: {}

kafka_customers_logs_cluster_ha: # estimated max cluster size: 96 GiB + customers offsets => 50GiB per node
  kafka_topics_default_partitions: 12
  kafka_topics_default_replication: 2
  log_level: 'INFO'
  kafka_broker_config:
    log.cleanup.policy: 'delete'
    log.retention.bytes: "268435456" # 256 MiB, per partition
    log.segment.bytes: "134217728"   # 128 MiB max per segment
    log.roll.ms: "1200000"           # a segment will be used (written) for max 20mn (after 20mn, a new file is created)
    log.retention.ms: "43200000"     # 12h
  topics:
    tpsvclogs:
      topic_options:
        retention.ms: "43200000"      # 12h
        retention.bytes: "4294967296" # 4GiB per partition

kafka_applications_cluster_ha: # estimated max cluster size: 78 GiB + customers offsets = 30 GiB per node
  kafka_topics_default_partitions: 12
  kafka_topics_default_replication: 2
  log_level: 'INFO'
  kafka_broker_config:
    log.cleanup.policy: 'delete'
    log.retention.bytes: "134217728" # 128 MiB, per partition => default topic sizing: 12 * 128MiB * 2 = 3 GB per topic on cluster
    log.segment.bytes: "67108864"    # 64 MiB max per segment
    log.roll.ms: "1200000"           # a segment will be used (written) for max 20mn (after 20mn, a new file is created)
    log.retention.ms: "43200000"     # 12h
  topics:
    dispatcher: {}
    container-manager: {}
    container-events: {}
    output: {}
    data-history: {}
    schemas: {}
    schemas-references: {}
    dataset-changed:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    datastore-changed:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    app-to-runtime:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    runtime-to-app:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    notifications: {}
    websocket-to-app:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    app-to-websocket:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    logs-runtime-to-app:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    userflow-changed:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    impact-analysis-batch: {}
    dqDictionary:
      topic_options:
        retention.bytes: "536870912" # 512 MiB per partition => 12GiB per cluster
        retention.ms: "648000000" # 7.5d
        segment.ms: "3600000"     # 1h
    dataprep:
      topic_options:
        retention.ms: "1800000" # 30min
        segment.ms: "300000"    # 5mn
    dataprep-unique:
      topic_options:
        retention.ms: "1800000" # 30min
        segment.ms: "300000"    # 5mn
    dataprep-broadcast:
      topic_options:
        retention.ms: "1800000" # 30min
        segment.ms: "300000"    # 5mn
    provisioning: {}
    rating-changed:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn

kafka_applications_cluster_simple:   # estimated max data size: 27 GiB + customer_offsets
  kafka_topics_default_partitions: 2
  kafka_topics_default_replication: 1
  kafka_broker_config:
    log.cleanup.policy: 'delete'
    log.retention.bytes: "536870912" # 512MiB
    log.segment.bytes: "67108864"    # 64 MiB max per segment
    log.roll.ms: "1200000"           # a segment will be used (written) for max 20mn (after 20mn, a new file is created)
    log.retention.ms: "43200000"     # 12h
  topics:
    dispatcher: {}
    container-manager: {}
    container-events: {}
    output: {}
    data-history: {}
    schemas: {}
    schemas-references: {}
    dataset-changed:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    datastore-changed:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    app-to-runtime:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    runtime-to-app:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    notifications: {}
    websocket-to-app:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    app-to-websocket:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    logs-app-to-runtime:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    logs-runtime-to-app:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    userflow-changed:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn
    impact-analysis-batch: {}
    dqDictionary:
      topic_options:
        retention.bytes: "2684354560" # 2,5GiB
        retention.ms: "648000000" # 7.5d
        segment.ms: "3600000"     # 1h
    dataprep:
      topic_options:
        retention.ms: "1800000" # 30min
        segment.ms: "300000"    # 5mn
    dataprep-unique:
      topic_options:
        retention.ms: "1800000" # 30min
        segment.ms: "300000"    # 5mn
    dataprep-broadcast:
      topic_options:
        retention.ms: "1800000" # 30min
        segment.ms: "300000"    # 5mn
    provisioning: {}
    rating-changed:
      topic_options:
        retention.ms: "3600000" # 1H
        segment.ms: "300000"    # 5mn

# Example of tuning for profiling kafka:
# <kafka_yaml_profile_name>:
#   kafka_version: '0.10.2.1' # if absent, use profile::kafka::kafka_version
#   scala_version: '2.11'     # if absent, use profile::kafka::scala_version
#   log_level: 'INFO'         # if absent, use profile::kafka::log_level
#   kafka_topics_default_replication: 1 # if absent, use profile::kafka::kafka_topics_default_replication
#   kafka_topics_default_partitions: 6  # if absent, use profile::kafka::kafka_topics_default_partitions
#   kafka_broker_config:  # a merge is done between this hash, profile::kafka::kafka_broker_config and the default
#     log.cleanup.policy: 'delete'
#     log.retention.bytes: "536870912"
#     log.retention.ms: "43200000"
#   topics:  # a merge is done between this hash and profile::kafka::kafka_topics_config
#     <topic1name>:
#       replication_factor: 1
#       partitions: 1
#       topic_options: # https://kafka.apache.org/documentation/#topic-config
#         retention.bytes: "1073741824"
#     <topic2name_all_default>: {}
#
